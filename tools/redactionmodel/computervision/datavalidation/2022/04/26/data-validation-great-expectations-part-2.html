<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to trust the data you feed your model: data validation with Great Expectations in a computer vision context (part 2) | mlops.systems</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="How to trust the data you feed your model: data validation with Great Expectations in a computer vision context (part 2)" />
<meta name="author" content="Alex Strick van Linschoten" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this second post on data validation for the computer vision context, I show how you can use the automatic profiling feature of Great Expectations to get you started with increasing your confidence in your object detection annotations." />
<meta property="og:description" content="In this second post on data validation for the computer vision context, I show how you can use the automatic profiling feature of Great Expectations to get you started with increasing your confidence in your object detection annotations." />
<link rel="canonical" href="https://mlops.systems/tools/redactionmodel/computervision/datavalidation/2022/04/26/data-validation-great-expectations-part-2.html" />
<meta property="og:url" content="https://mlops.systems/tools/redactionmodel/computervision/datavalidation/2022/04/26/data-validation-great-expectations-part-2.html" />
<meta property="og:site_name" content="mlops.systems" />
<meta property="og:image" content="https://mlops.systems/images/great_expectations/g_e_logo.jpeg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-04-26T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2022-04-26T00:00:00-05:00","url":"https://mlops.systems/tools/redactionmodel/computervision/datavalidation/2022/04/26/data-validation-great-expectations-part-2.html","@type":"BlogPosting","dateModified":"2022-04-26T00:00:00-05:00","image":"https://mlops.systems/images/great_expectations/g_e_logo.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlops.systems/tools/redactionmodel/computervision/datavalidation/2022/04/26/data-validation-great-expectations-part-2.html"},"author":{"@type":"Person","name":"Alex Strick van Linschoten"},"headline":"How to trust the data you feed your model: data validation with Great Expectations in a computer vision context (part 2)","description":"In this second post on data validation for the computer vision context, I show how you can use the automatic profiling feature of Great Expectations to get you started with increasing your confidence in your object detection annotations.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mlops.systems/feed.xml" title="mlops.systems" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script
  defer
  data-domain="mlops.systems"
  src="https://plausible.io/js/plausible.js"
></script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">mlops.systems</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to trust the data you feed your model: data validation with Great Expectations in a computer vision context (part 2)</h1><p class="page-description">In this second post on data validation for the computer vision context, I show how you can use the automatic profiling feature of Great Expectations to get you started with increasing your confidence in your object detection annotations.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-04-26T00:00:00-05:00" itemprop="datePublished">
        Apr 26, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Alex Strick van Linschoten</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#tools">tools</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#redactionmodel">redactionmodel</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#computervision">computervision</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#datavalidation">datavalidation</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#tldr-for-data-validation-with-great-expectations">TL;DR for data validation with Great Expectations</a></li>
<li class="toc-entry toc-h2"><a href="#initial-notebook-based-setup">Initial notebook-based setup</a></li>
<li class="toc-entry toc-h2"><a href="#using-the-great-expectations-profiler">Using the Great Expectations Profiler</a></li>
<li class="toc-entry toc-h2"><a href="#viewing-data-docs-reports-on-validated-data">Viewing Data Docs reports on validated data</a></li>
</ul><p><em>(This is part of a series of blog posts documenting my work to train a model that detects redactions in documents. To read other posts, check out <a href="https://mlops.systems/categories/#redactionmodel">the <code class="language-plaintext highlighter-rouge">redactionmodel</code> taglist</a>.)</em></p>

<p>In <a href="https://mlops.systems/tools/redactionmodel/computervision/2022/04/19/data-validation-great-expectations-part-1.html">the first part</a> of this series, I made the case for why you might want to include some kind of data validation if you’re working on training a model in general, and if your working on object detection in specific. There are many things that can go wrong with your data inputs and you ought to have some kind of safeguards in place to prevent some tricky failures and bugs.</p>

<h2 id="tldr-for-data-validation-with-great-expectations">
<a class="anchor" href="#tldr-for-data-validation-with-great-expectations" aria-hidden="true"><span class="octicon octicon-link"></span></a>TL;DR for data validation with Great Expectations</h2>

<ul>
  <li>👀 Data validation helps give you confidence in the raw ingredients that feed into your models, especially in scenarios where you retrain or fine-tune regularly.</li>
  <li>✅ For object detection problems, there are many ways your data can fail in some silent way. You should want to be aware of when your training data isn’t meeting your assumptions of what it should look like.</li>
  <li>🛠 Great Expectations is a general purpose data validation tool that goes a long way to restoring trust in your data, and their automatic profiling feature is really useful when getting started.</li>
</ul>

<h2 id="initial-notebook-based-setup">
<a class="anchor" href="#initial-notebook-based-setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initial notebook-based setup</h2>

<p>In <a href="https://mlops.systems/tools/redactionmodel/computervision/2022/04/19/data-validation-great-expectations-part-1.html">the last post</a> I showed how you can easily use Great Expectations directly on a Pandas <code class="language-plaintext highlighter-rouge">DataFrame</code>, manually specifying values you expect to be the case for your data. For example, perhaps your data should always have certain columns, or the values of a certain column should always be a certain type or mostly range between certain values. You can <a href="https://docs.greatexpectations.io/docs/guides/expectations/how_to_create_and_edit_expectations_based_on_domain_knowledge_without_inspecting_data_directly">define all these fairly easily</a>, leveraging your domain knowledge of the data.</p>

<p>If you know you’re going to want to use Great Expectations as a more fully-fledged part of your pipeline or workflow, you’ll probably want to go through the more extensive setup stages and create a dedicated ‘context’ which can be longer-lasting than just length of your script runtime. Think of the ‘context’ as somewhere all your expectations and configuration of how to access your data is stored.</p>

<p>Full instructions on how to set all this up can be found <a href="https://docs.greatexpectations.io/docs/guides/setup/setup_overview/">in the docs</a>, but for the most part it’s a matter of <code class="language-plaintext highlighter-rouge">pip</code> installing Great Expectations, running <code class="language-plaintext highlighter-rouge">great_expectations init</code> , and then <code class="language-plaintext highlighter-rouge">great_expectations datasource new</code>.</p>

<p>That final command will take you through an interactive setup that has you fill in and amend Jupyter notebooks. (I’m not fully sold on the prominence of this workflow that has you spinning up a Jupyter runtime, dynamically editing notebooks and so on, but I found doing it for my project wasn’t as inconvenient as I’d expected. Plus, there are non-interactive and pure Pythonic ways to get everything configured if you need or prefer that.)</p>

<p>Once you have your context created and your data sources connected, you can move on to the main course: using <a href="https://docs.greatexpectations.io/docs/terms/profiler">the Profiler</a>.</p>

<h2 id="using-the-great-expectations-profiler">
<a class="anchor" href="#using-the-great-expectations-profiler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using the Great Expectations Profiler</h2>

<p>Setting up your validations (i.e. your ‘expectations’) for your data can be done in a number of different ways. We saw <a href="https://mlops.systems/tools/redactionmodel/computervision/2022/04/19/data-validation-great-expectations-part-1.html">last time</a> how you can define these manually, but in this post I want to show how you can follow another recommended workflow by allowing the profiler to review your data and to make an initial set of assumptions about the boundaries and patterns embedded in those values.</p>

<p>Note, <a href="https://docs.greatexpectations.io/docs/guides/expectations/how_to_create_and_edit_expectations_with_a_profiler/">as the docs mention</a>, the expectations that are automatically generated from your dataset are “deliberately over-fitted on your data”. This means that if your <code class="language-plaintext highlighter-rouge">DataFrame</code> has 10,321 rows, one of the expectations generated will be that datasets due for validation with this suite of expectations will also have exactly 10,321 rows:</p>

<blockquote>
  <p>“The intention is for this Expectation Suite to be edited and updated to better suit your specific use case - it is not specifically intended to be used as is.” (<a href="https://docs.greatexpectations.io/docs/guides/expectations/how_to_create_and_edit_expectations_with_a_profiler/">source</a>)</p>
</blockquote>

<p>You’ll want and have to do a decent amount of manual checking through, amending and updating any expectations that get created during this process. That said, I am finding that it makes a lot of sense to start with some kind of initial baseline of assumptions that can be corrected versus starting from complete zero and building things up purely based on your domain knowledge of the data.</p>

<p>Needless to say, this whole process assumes you have a decent grasp on the domain context and have explored your data already. You probably wouldn’t go to the trouble of setting up Great Expectations if you were doing something that required only a quick solution, but it bears repeating that the expectations you define are only as good as your understanding of the limits and underlying realities of your data. This is probably why something like Great Expectations lends itself quite well to a data-centric approach.</p>

<p>Getting the profiler to work requires a few interlocking abstractions to be created or instantiated:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">expectation_suite_name</span> <span class="o">=</span> <span class="s">"redaction_annotations_suite"</span>

<span class="n">main_batch_request</span> <span class="o">=</span> <span class="n">RuntimeBatchRequest</span><span class="p">(</span>
    <span class="n">datasource_name</span><span class="o">=</span><span class="s">"redaction_data"</span><span class="p">,</span>
    <span class="n">data_connector_name</span><span class="o">=</span><span class="s">"default_runtime_data_connector_name"</span><span class="p">,</span>
    <span class="n">data_asset_name</span><span class="o">=</span><span class="s">"main_annotations_df"</span><span class="p">,</span>  <span class="c1"># This can be anything that identifies this data_asset for you
</span>    <span class="n">runtime_parameters</span><span class="o">=</span><span class="p">{</span><span class="s">"batch_data"</span><span class="p">:</span> <span class="n">main_annotations_df</span><span class="p">},</span>  <span class="c1"># df is your dataframe
</span>    <span class="n">batch_identifiers</span><span class="o">=</span><span class="p">{</span><span class="s">"default_identifier_name"</span><span class="p">:</span> <span class="s">"default_identifier"</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">context</span><span class="p">.</span><span class="n">create_expectation_suite</span><span class="p">(</span>
    <span class="n">expectation_suite_name</span><span class="o">=</span><span class="n">expectation_suite_name</span><span class="p">,</span> <span class="n">overwrite_existing</span><span class="o">=</span><span class="bp">True</span> <span class="c1"># toggle this as appropriate
</span><span class="p">)</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">get_validator</span><span class="p">(</span>
    <span class="n">batch_request</span><span class="o">=</span><span class="n">main_batch_request</span><span class="p">,</span> <span class="n">expectation_suite_name</span><span class="o">=</span><span class="n">expectation_suite_name</span>
<span class="p">)</span>

<span class="n">profiler</span> <span class="o">=</span> <span class="n">UserConfigurableProfiler</span><span class="p">(</span><span class="n">profile_dataset</span><span class="o">=</span><span class="n">validator</span><span class="p">)</span>
<span class="n">suite</span> <span class="o">=</span> <span class="n">profiler</span><span class="p">.</span><span class="n">build_suite</span><span class="p">()</span>
<span class="n">context</span><span class="p">.</span><span class="n">save_expectation_suite</span><span class="p">(</span><span class="n">suite</span><span class="p">)</span> <span class="c1"># use this to save your suite in the context for reuse
</span></code></pre></div></div>

<p>The above code perhaps seems like a lot, but really all you’re doing is getting your data, making the relevant connections between Great Expectations and your context, and then running the profiler so it can work its magic.</p>

<p><img src="/images/great_expectations/profiler.jpg" alt="" title="You'll see output from the final `build_suite()` call that looks something like this."></p>

<p>You can’t yet see the specific values that were imputed from your data, but even this high-level output shows you some of the expectations that it’s thinking would be useful to create.</p>

<p>At this stage, you’ll want to take some time to review the specific expectations. You’ll want to:</p>

<ul>
  <li>ensure that they make sense for your dataset</li>
  <li>remove any of the really rigid expectations (e.g. that any dataset must have exactly the same number of rows)</li>
  <li>use the inputed expectations as a springboard for any other ideas that might come to mind</li>
</ul>

<p>Note that this is an essential step to complete before moving forward. You could use the unedited auto-generated expectations suite as your data validation, but it would almost certainly have little use or value for you. <em>The auto-generated suite is a starting place that you need to amend and tailor to your specific situation.</em></p>

<p>In my case, I was able to amend some of the <code class="language-plaintext highlighter-rouge">min</code> / <code class="language-plaintext highlighter-rouge">max</code> values to more suitable defaults. (You amend these expectations in the <code class="language-plaintext highlighter-rouge">.json</code> file that was created inside the <code class="language-plaintext highlighter-rouge">expectations</code> subfolder within your context.) I also included some other domain-driven expectations that the profiler couldn’t have known to include. For example, I know from having immersed myself in this data for several months now that most annotations should have a ‘horizontal’ or ‘square’ orientation. Great Expectations doesn’t create this expectation automatically, so I add it to the list of basic assumptions already generated.</p>

<h2 id="viewing-data-docs-reports-on-validated-data">
<a class="anchor" href="#viewing-data-docs-reports-on-validated-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Viewing Data Docs reports on validated data</h2>

<p>Once you have a suite of expectations set up to your liking, you can run a checkpoint against your original data just to make sure you haven’t introduced or amended something that doesn’t match up with the original data. You should get no errors at this point.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"name"</span><span class="p">:</span> <span class="s">"my_checkpoint"</span><span class="p">,</span>
    <span class="s">"config_version"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">"class_name"</span><span class="p">:</span> <span class="s">"SimpleCheckpoint"</span><span class="p">,</span>
    <span class="s">"validations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s">"batch_request"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">"datasource_name"</span><span class="p">:</span> <span class="s">"redaction_data"</span><span class="p">,</span>
                <span class="s">"data_connector_name"</span><span class="p">:</span> <span class="s">"default_runtime_data_connector_name"</span><span class="p">,</span>
                <span class="s">"data_asset_name"</span><span class="p">:</span> <span class="s">"main_annotations_df"</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s">"expectation_suite_name"</span><span class="p">:</span> <span class="n">expectation_suite_name</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">}</span>
<span class="n">context</span><span class="p">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="o">**</span><span class="n">checkpoint_config</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">run_checkpoint</span><span class="p">(</span>
    <span class="n">checkpoint_name</span><span class="o">=</span><span class="s">"my_checkpoint"</span><span class="p">,</span>
    <span class="n">batch_request</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"runtime_parameters"</span><span class="p">:</span> <span class="p">{</span><span class="s">"batch_data"</span><span class="p">:</span> <span class="n">main_annotations_df</span><span class="p">},</span>
        <span class="s">"batch_identifiers"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"default_identifier_name"</span><span class="p">:</span> <span class="s">"default_identifier"</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">context</span><span class="p">.</span><span class="n">build_data_docs</span><span class="p">()</span> <span class="c1"># builds data docs to inspect the results
</span></code></pre></div></div>

<p>What you really want, however, is to run your expectations suite against <em>new</em> data. That’s the real value of what Great Expectations brings, i.e. to check that incoming data due to be added to your larger base dataset conforms to the broad realities of that base dataset.</p>

<p>In my case, the first thing I was interested to check was whether <a href="https://mlops.systems/redactionmodel/computervision/python/tools/2022/02/10/synthetic-image-data.html">the synthetic images</a> <a href="https://mlops.systems/tools/redactionmodel/computervision/2022/04/06/synthetic-data-results.html">I created</a> would match the expectations suite I’d created based off my core hand-annotated data. (Quick context if you haven’t been following the project so far: I have a core dataset which is manually annotated for the objects inside images. I also created two sets of synthetic data to supplement the manual annotations, which <a href="https://mlops.systems/tools/redactionmodel/computervision/2022/04/06/synthetic-data-results.html">boosted my model performance</a> considerably.)</p>

<p><img src="/images/great_expectations/ge_ui_validation.png" alt="" title="The web validation UI looks like this once you generate and open it."></p>

<p>The web UI is where you can go to get a visual overview of where your data is passing and failing to meet your (great) expectations. You will want (and I will need) to configure your expectations suite to meet the core assumptions you make about your data derived from your particular domain.</p>

<p>For my case, some expectations I will add that are specific to my use case:</p>

<ul>
  <li>redaction annotations should mostly be of horizontal orientation</li>
  <li>content annotations should mostly be of portrait orientation</li>
  <li>most images should have only one content annotation</li>
  <li>annotations shouldn’t be larger than the associated image, or positioned outside the boundaries of that image. (Because of how you define them, in reality this is several expectations, but conceptually it’s just one or two).</li>
  <li>the area taken up by most annotations should be less than half that taken up by the total image</li>
</ul>

<p>…and so on. I hope it’s clear now how Great Expectations can be a tremendous asset that can give you confidence in your data.</p>

<p>In the next and final post of the series, I will explore some other tools that you can consider when performing these kinds of validation. I will also offer my take on when each tool would be appropriate, as well as where they would be appropriate to use within the machine learning workflow and lifecycle.</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="strickvl/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/tools/redactionmodel/computervision/datavalidation/2022/04/26/data-validation-great-expectations-part-2.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A place to share my technical learnings.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/strickvl" target="_blank" title="strickvl"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/strickvl" target="_blank" title="strickvl"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
